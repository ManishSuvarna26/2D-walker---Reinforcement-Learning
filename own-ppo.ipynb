{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import random\n",
    "\n",
    "import gym\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.distributions import Normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Use CUDA</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_cuda = torch.cuda.is_available()\n",
    "device   = torch.device(\"cuda\" if use_cuda else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Create Environments</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing_env import SubprocVecEnv\n",
    "\n",
    "num_envs = 16\n",
    "env_name = \"Pendulum-v0\"\n",
    "\n",
    "def make_env():\n",
    "    def _thunk():\n",
    "        env = gym.make(env_name)\n",
    "        return env\n",
    "\n",
    "    return _thunk\n",
    "\n",
    "envs = [make_env() for i in range(num_envs)]\n",
    "envs = SubprocVecEnv(envs)\n",
    "\n",
    "env = gym.make(env_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Neural Network</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_weights(m):\n",
    "    if isinstance(m, nn.Linear):\n",
    "        nn.init.normal_(m.weight, mean=0., std=0.1)\n",
    "        nn.init.constant_(m.bias, 0.1)\n",
    "        \n",
    "\n",
    "class ActorCritic(nn.Module):\n",
    "    def __init__(self, num_inputs, num_outputs, hidden_size, std=0.0):\n",
    "        super(ActorCritic, self).__init__()\n",
    "        \n",
    "        self.critic = nn.Sequential(\n",
    "            nn.Linear(num_inputs, hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_size, 1)\n",
    "        )\n",
    "        \n",
    "        self.actor = nn.Sequential(\n",
    "            nn.Linear(num_inputs, hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_size, num_outputs),\n",
    "        )\n",
    "        self.log_std = nn.Parameter(torch.ones(1, num_outputs) * std)\n",
    "        \n",
    "        self.apply(init_weights)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        value = self.critic(x)\n",
    "        mu    = self.actor(x)\n",
    "        std   = self.log_std.exp().expand_as(mu)\n",
    "        dist  = Normal(mu, std)\n",
    "        return dist, value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(frame_idx, rewards):\n",
    "    clear_output(True)\n",
    "    plt.figure(figsize=(20,5))\n",
    "    plt.subplot(131)\n",
    "    plt.title('frame %s. reward: %s' % (frame_idx, rewards[-1]))\n",
    "    plt.plot(rewards)\n",
    "    plt.show()\n",
    "    \n",
    "def test_env(vis=False):\n",
    "    state = env.reset()\n",
    "    if vis: env.render()\n",
    "    done = False\n",
    "    total_reward = 0\n",
    "    while not done:\n",
    "        state = torch.FloatTensor(state).unsqueeze(0).to(device)\n",
    "        dist, _ = model(state)\n",
    "        next_state, reward, done, _ = env.step(dist.sample().cpu().numpy()[0])\n",
    "        state = next_state\n",
    "        if vis: env.render()\n",
    "        total_reward += reward\n",
    "    return total_reward"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>GAE</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_gae(next_value, rewards, masks, values, gamma=0.99, tau=0.95):\n",
    "    values = values + [next_value]\n",
    "    gae = 0\n",
    "    returns = []\n",
    "    for step in reversed(range(len(rewards))):\n",
    "        delta = rewards[step] + gamma * values[step + 1] * masks[step] - values[step]\n",
    "        gae = delta + gamma * tau * masks[step] * gae\n",
    "        returns.insert(0, gae + values[step])\n",
    "    return returns\n",
    "\n",
    "# Calculate the generalized advantage estimation\n",
    "def calculate_gae(tau, time_horizon, gamma, advantages):\n",
    "    gaes = []\n",
    "    prev_gae = []\n",
    "\n",
    "    # Start with the last sample and move backwards \n",
    "    for i in range(time_horizon, 0, -1):\n",
    "        advantage = rewards[i] + gamma*state_values[i]*terminal_state[i] - next_state_values[i]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Proximal Policy Optimization Algorithm</h1>\n",
    "<h2><a href=\"https://arxiv.org/abs/1707.06347\">Arxiv</a></h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ppo_iter(mini_batch_size, states, actions, log_probs, returns, advantage):\n",
    "    batch_size = states.size(0)\n",
    "    for _ in range(batch_size // mini_batch_size):\n",
    "        rand_ids = np.random.randint(0, batch_size, mini_batch_size)\n",
    "        yield states[rand_ids, :], actions[rand_ids, :], log_probs[rand_ids, :], returns[rand_ids, :], advantage[rand_ids, :]\n",
    "        \n",
    "        \n",
    "\n",
    "def ppo_update(ppo_epochs, mini_batch_size, states, actions, log_probs, returns, advantages, clip_param=0.2):\n",
    "    for _ in range(ppo_epochs):\n",
    "        for state, action, old_log_probs, return_, advantage in ppo_iter(mini_batch_size, states, actions, log_probs, returns, advantages):\n",
    "            dist, value = model(state)\n",
    "            entropy = dist.entropy().mean()\n",
    "            new_log_probs = dist.log_prob(action)\n",
    "\n",
    "            ratio = (new_log_probs - old_log_probs).exp()\n",
    "            surr1 = ratio * advantage\n",
    "            surr2 = torch.clamp(ratio, 1.0 - clip_param, 1.0 + clip_param) * advantage\n",
    "\n",
    "            actor_loss  = - torch.min(surr1, surr2).mean()\n",
    "            critic_loss = (return_ - value).pow(2).mean()\n",
    "\n",
    "            loss = 0.5 * critic_loss + actor_loss - 0.001 * entropy\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "def ppo_iter(mini_batch_size, states, actions, log_probs, returns, advantage):\n",
    "    \n",
    "    batch_size = states.size(0)\n",
    "    for _ in range(batch_size // mini_batch_size):\n",
    "        rand_ids = np.random.randint(0, batch_size, mini_batch_size)\n",
    "        yield states[rand_ids, :], actions[rand_ids, :], log_probs[rand_ids, :], returns[rand_ids, :], advantage[rand_ids, :]\n",
    "        \n",
    "        \n",
    "\n",
    "def ppo_update(ppo_epochs, mini_batch_size, states, actions, log_probs, returns, advantages, clip_param=0.2):\n",
    "    for _ in range(ppo_epochs):\n",
    "        for state, action, old_log_probs, return_, advantage in ppo_iter(mini_batch_size, states, actions, log_probs, returns, advantages):\n",
    "            \n",
    "            entropy_coefficient = 0.001\n",
    "            distance,value = model(state)\n",
    "            # Calculating the entropy for the yielded distance\n",
    "            entropy = distance.entropy().mean()\n",
    "            new_log_probs = distance.log_prob(action)\n",
    "\n",
    "            ratio = (new_log_probs - old_log_probs).exp()\n",
    "            surr1 = ratio * advantage\n",
    "            clipped_objective  = - torch.min(ratio*advantage, torch.clamp(ratio, 1.0 - clip_param, 1.0 + clip_param) * advantage)\n",
    "            critic_loss = (return_ - value).pow(2)\n",
    "            critic_mean_loss = critic_loss.mean()\n",
    "            actor_mean_loss = clipped_objective.mean()\n",
    "            loss = 0.5 * critic_mean_loss + actor_mean_loss - entropy_coefficient * entropy\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_inputs  = envs.observation_space.shape[0]\n",
    "num_outputs = envs.action_space.shape[0]\n",
    "\n",
    "#Hyper params:\n",
    "hidden_size      = 256\n",
    "lr               = 3e-4\n",
    "num_steps        = 20*16\n",
    "mini_batch_size  = 5\n",
    "ppo_epochs       = 4\n",
    "threshold_reward = -200\n",
    "discount_factor = 0.99\n",
    "lambda_ = 0.95\n",
    "\n",
    "model = ActorCritic(num_inputs, num_outputs, hidden_size).to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_frames = 1500000000000\n",
    "frame_idx  = 0\n",
    "test_rewards = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "state = envs.reset()\n",
    "early_stop = False\n",
    "\n",
    "while frame_idx < max_frames and not early_stop:\n",
    "\n",
    "    log_probs = []\n",
    "    values    = []\n",
    "    states    = []\n",
    "    actions   = []\n",
    "    rewards   = []\n",
    "    terminal_states     = []\n",
    "    entropy = 0\n",
    "\n",
    "    for _ in range(num_steps):\n",
    "        state = torch.FloatTensor(state).to(device)\n",
    "        dist, value = model(state)\n",
    "\n",
    "        action = dist.sample()\n",
    "        next_state, reward, done, _ = envs.step(action.cpu().numpy())\n",
    "\n",
    "        log_prob = dist.log_prob(action)\n",
    "        entropy += dist.entropy().mean()\n",
    "        \n",
    "        log_probs.append(log_prob)\n",
    "        values.append(value)\n",
    "        rewards.append(torch.FloatTensor(reward).unsqueeze(1).to(device))\n",
    "        terminal_states.append(torch.FloatTensor(1 - done).unsqueeze(1).to(device))\n",
    "        \n",
    "        states.append(state)\n",
    "        actions.append(action)\n",
    "        \n",
    "        state = next_state\n",
    "        frame_idx += 1\n",
    "        \n",
    "        if frame_idx % 1000 == 0:\n",
    "            test_reward = np.mean([evaluate_agent(False) for _ in range(10)])\n",
    "            test_rewards.append(test_reward)\n",
    "            plot(frame_idx, test_rewards)\n",
    "            if test_reward > threshold_reward: early_stop = True\n",
    "            \n",
    "\n",
    "    next_state = torch.FloatTensor(next_state).to(device)\n",
    "    _, next_value = model(next_state)\n",
    "    state_values = values + [next_value]\n",
    "    advantages = calculate_advantage(rewards, state_values, discount_factor, terminal_states)\n",
    "    gaes = calculate_gae(lambda_, num_steps, discount_factor, advantages, terminal_states, state_values)\n",
    "    #returns = compute_gae(next_value, rewards, terminal_states, values)\n",
    "    \n",
    "    \n",
    "\n",
    "    #returns   = torch.cat(returns).detach()\n",
    "    log_probs = torch.cat(log_probs).detach()\n",
    "    values    = torch.cat(values).detach()\n",
    "    states    = torch.cat(states)\n",
    "    actions   = torch.cat(actions)\n",
    "    returns   = (torch.cat(gaes) + values).detach()\n",
    "    gaes      = torch.cat(gaes).detach()\n",
    "    \n",
    "    ppo_update(ppo_epochs, mini_batch_size, states, actions, log_probs, returns, gaes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This evaluates the agent\n",
    "def evaluate_agent(vis):\n",
    "    if vis: env.render()\n",
    "    state = env.reset()\n",
    "    in_terminal_state = False\n",
    "    total_reward = 0\n",
    "    while not in_terminal_state:\n",
    "        state = torch.FloatTensor(state).reshape(1,-1).to(device)\n",
    "        dist, _ = model(state)\n",
    "        next_state, reward, in_terminal_state, _ = env.step(dist.sample().cpu().numpy()[0])\n",
    "        state = next_state\n",
    "        total_reward += reward\n",
    "        #time.sleep(1/60)\n",
    "\n",
    "    #final_location_x = env.robot.get_location()[0]\n",
    "\n",
    "    return total_reward#, final_location_x\n",
    "\n",
    "\n",
    "\n",
    "def calculate_advantage(rewards, state_values, gamma, terminal_state):\n",
    "    # Convert the lists into torch tensors\n",
    "    #print(state_values)\n",
    "    next_values = torch.stack(state_values[1:])\n",
    "    prev_values = torch.stack(state_values[0:-1])\n",
    "    terminal_state = torch.stack(terminal_state)\n",
    "    rewards = torch.stack(rewards)\n",
    "    \n",
    "    # Calculate the advantages\n",
    "    advantage = rewards + gamma*next_values*terminal_state - prev_values\n",
    "    return advantage\n",
    "\n",
    "def compute_gae(next_value, rewards, masks, values, gamma=0.99, tau=0.95):\n",
    "    values = values + [next_value]\n",
    "    gae = 0\n",
    "    returns = []\n",
    "    for step in reversed(range(len(rewards))):\n",
    "        delta = rewards[step] + gamma * values[step + 1] * masks[step] - values[step]\n",
    "        gae = delta + gamma * tau * masks[step] * gae\n",
    "        returns.insert(0, gae + values[step])\n",
    "    return returns\n",
    "\n",
    "# Calculate the generalized advantage estimation\n",
    "def calculate_gae(lambda_, num_steps, gamma, advantages, terminal_states, state_values):\n",
    "    gaes = []\n",
    "    prev_gae = 0\n",
    "    \n",
    "    # Convert the lists to tensors\n",
    "    terminal_states = torch.stack(terminal_states)\n",
    "\n",
    "    # Start with the last sample and move backwards \n",
    "    for i in range(num_steps-1, -1, -1):\n",
    "        gae = advantages[i] + gamma*lambda_*terminal_states[i]*prev_gae\n",
    "        #gaes.insert(0, gae)\n",
    "        gaes.append(gae)\n",
    "        prev_gae = gae\n",
    "        \n",
    "    # The list in the backwards order. Return it flipped\n",
    "    return gaes[::-1]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Saving trajectories for GAIL</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import count\n",
    "\n",
    "max_expert_num = 50000\n",
    "num_steps = 0\n",
    "expert_traj = []\n",
    "\n",
    "for i_episode in count():\n",
    "    state = env.reset()\n",
    "    done = False\n",
    "    total_reward = 0\n",
    "    \n",
    "    while not done:\n",
    "        state = torch.FloatTensor(state).unsqueeze(0).to(device)\n",
    "        dist, _ = model(state)\n",
    "        action = dist.sample().cpu().numpy()[0]\n",
    "        next_state, reward, done, _ = env.step(action)\n",
    "        state = next_state\n",
    "        total_reward += reward\n",
    "        expert_traj.append(np.hstack([state, action]))\n",
    "        num_steps += 1\n",
    "    \n",
    "    print(\"episode:\", i_episode, \"reward:\", total_reward)\n",
    "    \n",
    "    if num_steps >= max_expert_num:\n",
    "        break\n",
    "        \n",
    "expert_traj = np.stack(expert_traj)\n",
    "print()\n",
    "print(expert_traj.shape)\n",
    "print()\n",
    "np.save(\"expert_traj.npy\", expert_traj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
